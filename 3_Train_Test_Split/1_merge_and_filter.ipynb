{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge results from other methods benchmark and parsed Socket assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socket = pickle.load(open('./../1_Data_Preparation/out/pickle/data_all_74.p', 'rb'))\n",
    "df_pcoils = pickle.load(open('./../1_Data_Preparation/out/pickle/pcoils_all_74.p', 'rb'))\n",
    "df_marcoil = pickle.load(open('./../1_Data_Preparation/out/pickle/marcoil_all_74.p', 'rb'))\n",
    "df_cchmmprof = pickle.load(open('./../1_Data_Preparation/out/pickle/cchmmprof_all_74.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_socket, df_cchmmprof, df_marcoil, df_pcoils], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sequences after filtering with cd-hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed some nearly identical sequences in  pdb50 dataset, therefore sequences obtained in data preparation part were additionally filtered with cd-hit to 50 % similarity.\n",
    "\n",
    "Command was: cd-hit -i all.fasta -o all.cdhit.fasta -c 0.5 -n 2 -T 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdhit_entries = set()\n",
    "from Bio import SeqIO\n",
    "for record in SeqIO.parse(\"filter/seq_db_cdhit.fasta\", \"fasta\"):\n",
    "    cdhit_entries.add(str(record.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cdhit'] = df.index.isin(cdhit_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute similarities of all sequences in the dataset. The goal is to find the sequences not more than 30 % similar to any sequence in the dataset. These will be placed in dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created blast database from all sequences in the dataset:\n",
    "\n",
    "Command was: makeblastdb -in all.cdhit.fasta -dbtype prot\n",
    "\n",
    "Afterwards each sequence was queried against the database to get the homologues.\n",
    "\n",
    "Command was: psiblast -query all.cdhit.fasta -db all.cdhit.fasta -outfmt \"6 qseqid sseqid pident qcovs evalue\" -evalue 1e-2 -num_threads 20 -max_target_seqs 2 > blast_all_cdhit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blast = pd.read_csv('./filter/seq_db_all.csv', sep='\\t', names=['qid','sid','ident', 'cov','evalue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "nohits = []\n",
    "for pdb in df_blast.groupby('qid'):\n",
    "    pdbid = pdb[0]\n",
    "    hits = pdb[1]\n",
    "    hits = hits[(hits['cov'] >= 0) & (hits['qid'] != hits['sid'])]\n",
    "    if len(hits)>0:\n",
    "        rows.append(hits.sort_values(by=['ident']).iloc[-1])\n",
    "    else:\n",
    "        nohits.append(pdbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blast = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "less30_entries = (set(df_blast[df_blast['ident'] < 30]['qid'].tolist()) | set(nohits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['less30'] = df.index.isin(less30_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get only entries after cd-hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24166, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['cdhit'] == True]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21783, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['sequence'].str.len() >= 25) & (df['sequence'].str.len() <=500)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Filter out half of negative sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12095, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df[df['cc'] == 1], df[df['cc'] == 0].sample(frac=0.5)])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to assure the equal distribution of CC-residues and non-CC-residues in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_count = df[df['cc'] == 1].shape[0]\n",
    "nocc_count = df[df['cc'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2407, 240.70000000000002, 9688, 968.8000000000001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_count, 0.1*cc_count, nocc_count, 0.1*nocc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00344050100573\n",
      "0.031063916913886134 0.030444019283737304 0.037325021295200475 0.00344050100573 1\n",
      "0.00209635467227\n",
      "0.031063916913886134 0.030688761202400983 0.03488147054693933 0.00209635467227 2\n",
      "0.000511523700378\n",
      "0.031063916913886134 0.030972109434537987 0.03199515683529456 0.000511523700378 3\n",
      "0.000192140278416\n",
      "0.031063916913886134 0.03102903821147502 0.0314133187683076 0.000192140278416 12\n",
      "8.88008489354e-05\n",
      "0.031063916913886134 0.031079866149868872 0.03090226445199808 8.88008489354e-05 39\n",
      "2.91307157614e-05\n",
      "0.031063916913886134 0.031058537815289517 0.031116799246812377 2.91307157614e-05 83\n",
      "1.60604586502e-05\n",
      "0.031063916913886134 0.031066847507276594 0.031034726589976143 1.60604586502e-05 185\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "pos_cc = ''.join(df['socket_assignment'].tolist()).count('1')\n",
    "neg_cc = ''.join(df['socket_assignment'].tolist()).count('0')\n",
    "all_frac = (pos_cc/(pos_cc+neg_cc))\n",
    "score = 1\n",
    "best = 1\n",
    "it = 0\n",
    "while score > 0.00002:\n",
    "    it += 1\n",
    "    df_temp = df.copy()\n",
    "    test_pos = df_temp[(df_temp['cc'] == 1) & (df_temp['less30'] == True)].sample(random.randrange(220, 260))\n",
    "    test_neg = df_temp[(df_temp['cc'] == 0) & (df_temp['less30'] == True)].sample(random.randrange(940, 990))\n",
    "    test = pd.concat((test_pos, test_neg))\n",
    "    df_temp.drop(test_pos.index, inplace=True)\n",
    "    df_temp.drop(test_neg.index, inplace=True)\n",
    "    train = df_temp\n",
    "    train_pos_cc = ''.join(train['socket_assignment'].tolist()).count('1')\n",
    "    train_neg_cc = ''.join(train['socket_assignment'].tolist()).count('0')\n",
    "    train_frac = (train_pos_cc/(train_pos_cc+train_neg_cc))\n",
    "    test_pos_cc = ''.join(test['socket_assignment'].tolist()).count('1')\n",
    "    test_neg_cc = ''.join(test['socket_assignment'].tolist()).count('0')\n",
    "    test_frac = (test_pos_cc/(test_pos_cc+test_neg_cc))\n",
    "    score = np.std((train_frac, test_frac))\n",
    "    if score < best:\n",
    "        print(score)\n",
    "        best = score\n",
    "        print(all_frac, train_frac, test_frac, best, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10895, 19), (1200, 19))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train for 5-fold cross validation|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again equal distribution of CC and non-CC residues must be assured in each validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017934543971 [0.03448993286074697, 0.02959011345647435, 0.029632527141623552, 0.03078359613849606, 0.030850831510413776] 1\n",
      "0.00110598604942 [0.03033043089975441, 0.033152431479504245, 0.030029100365302458, 0.03068553422832033, 0.031110182291419288] 2\n",
      "0.00080175151099 [0.032423861742063326, 0.030102752782926998, 0.03055064630331745, 0.030828998265973056, 0.03141335576964797] 10\n",
      "0.000646249162705 [0.02997316196614136, 0.03165086813702487, 0.03149816420000757, 0.030687486041837266, 0.031537000139011166] 13\n",
      "0.000527364876373 [0.030499902669841126, 0.03160713180794594, 0.03119052732133204, 0.030406203661842383, 0.03163737140963656] 36\n",
      "0.000399969123573 [0.030887770815285216, 0.030945999278020206, 0.03154269252871419, 0.03148382135838253, 0.030472786619535522] 46\n",
      "0.00035714335487 [0.03118591950323446, 0.031269543464665414, 0.030579649948872495, 0.03155687569909207, 0.03074280420730484] 314\n",
      "0.000312506758485 [0.03099356022272002, 0.030604236534564688, 0.03143753245865161, 0.030903993609030976, 0.03139087985597807] 547\n",
      "0.000227088199865 [0.031125101150893446, 0.030713951349841156, 0.03107634356468877, 0.03099853436160065, 0.0314206260072196] 841\n",
      "0.000224955268256 [0.03100083426289592, 0.030955402721963343, 0.03111158585659535, 0.031468557650547374, 0.03079689510233577] 1469\n",
      "0.000221616606517 [0.030959961047230235, 0.031107750444073178, 0.030832555250108806, 0.03147440993626921, 0.030959740798707714] 4093\n",
      "0.00021039555369 [0.031095151799061974, 0.03065682406721847, 0.03120773932642631, 0.031159747810965473, 0.03122157099607773] 6813\n",
      "0.000174861374669 [0.03137054327003552, 0.030900621118012422, 0.03113432551929392, 0.031023292410672268, 0.03090384332314136] 7391\n"
     ]
    }
   ],
   "source": [
    "score = 1\n",
    "best = 1\n",
    "it = 0\n",
    "while score > 0.0002:\n",
    "    it += 1\n",
    "    fractions = []\n",
    "    df_temp = train.copy()\n",
    "    df_temp = df_temp.sample(frac=1)\n",
    "    splits = np.array_split(df_temp, 5)\n",
    "    for split in splits:\n",
    "        pos_cc = ''.join(split['socket_assignment'].tolist()).count('1')\n",
    "        neg_cc = ''.join(split['socket_assignment'].tolist()).count('0')\n",
    "        frac = (pos_cc/(pos_cc+neg_cc))\n",
    "        fractions.append(frac)\n",
    "    score = np.std(fractions)\n",
    "    if score < best:\n",
    "        best = score\n",
    "        print(score, fractions, it)\n",
    "        c = 1\n",
    "        for split in splits:\n",
    "            split['val'] = c\n",
    "            if c == 1:\n",
    "                train_val = split\n",
    "            else:\n",
    "                train_val = pd.concat([train_val, split])\n",
    "            c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2179, 20), (2179, 20), (2179, 20), (2179, 20), (2179, 20))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val[train_val['val'] == 1].shape, train_val[train_val['val'] == 2].shape, train_val[train_val['val'] == 3].shape, train_val[train_val['val'] == 4].shape, train_val[train_val['val'] == 5].shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.to_pickle('out/train_data.p')\n",
    "train_val.to_csv('out/train_data.csv')\n",
    "test.to_pickle('out/test_data.p')\n",
    "test.to_csv('out/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
