{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge results from other methods benchmark and parsed Socket assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socket = pickle.load(open('./../1_Data_Preparation/out/pickle/data_all_74.p', 'rb'))\n",
    "df_pcoils = pickle.load(open('./../1_Data_Preparation/out/pickle/pcoils_all_74.p', 'rb'))\n",
    "df_marcoil = pickle.load(open('./../1_Data_Preparation/out/pickle/marcoil_all_74.p', 'rb'))\n",
    "df_cchmmprof = pickle.load(open('./../1_Data_Preparation/out/pickle/cchmmprof_all_74.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_socket, df_cchmmprof, df_marcoil, df_pcoils], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sequences after filtering with cd-hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed some nearly identical sequences in  pdb50 dataset, therefore sequences obtained in data preparation part were additionally filtered with cd-hit to 50 % similarity.\n",
    "\n",
    "Command was: cd-hit -i all.fasta -o all.cdhit.fasta -c 0.5 -n 2 -T 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdhit_entries = set()\n",
    "from Bio import SeqIO\n",
    "for record in SeqIO.parse(\"filter/seq_db_cdhit.fasta\", \"fasta\"):\n",
    "    cdhit_entries.add(str(record.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cdhit'] = df.index.isin(cdhit_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute similarities of all sequences in the dataset. The goal is to find the sequences not more than 30 % similar to any sequence in the dataset. These will be placed in dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created blast database from all sequences in the dataset:\n",
    "\n",
    "Command was: makeblastdb -in all.cdhit.fasta -dbtype prot\n",
    "\n",
    "Afterwards each sequence was queried against the database to get the homologues.\n",
    "\n",
    "Command was: psiblast -query all.cdhit.fasta -db all.cdhit.fasta -outfmt \"6 qseqid sseqid pident qcovs evalue\" -evalue 1e-2 -num_threads 20 -max_target_seqs 2 > blast_all_cdhit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blast = pd.read_csv('./filter/seq_db_all.csv', sep='\\t', names=['qid','sid','ident', 'cov','evalue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "nohits = []\n",
    "for pdb in df_blast.groupby('qid'):\n",
    "    pdbid = pdb[0]\n",
    "    hits = pdb[1]\n",
    "    hits = hits[(hits['cov'] >= 0) & (hits['qid'] != hits['sid'])]\n",
    "    if len(hits)>0:\n",
    "        rows.append(hits.sort_values(by=['ident']).iloc[-1])\n",
    "    else:\n",
    "        nohits.append(pdbid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blast = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "less30_entries = (set(df_blast[df_blast['ident'] < 30]['qid'].tolist()) | set(nohits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28939, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['less30'] = df.index.isin(less30_entries)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_res = set()\n",
    "f = open('./../5_Analyze_Results/resolu.idx')\n",
    "lines = f.readlines()\n",
    "for i in range(6, len(lines)):\n",
    "    data = lines[i].rstrip()\n",
    "    data = data.replace(\"\\t\", \"\")\n",
    "    pdb = data.split(';')[0]\n",
    "    try:\n",
    "        res = float(data.split(';')[1])\n",
    "        if res <= 4.0:\n",
    "            ok_res.add(pdb.lower())\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for index, value in df.iterrows():\n",
    "    pdb, chain = index.split('_')\n",
    "    if pdb in ok_res:\n",
    "        df.set_value(index, 'ok_res', True)\n",
    "    else:\n",
    "        df.set_value(index, 'ok_res', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28731, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['ok_res'] == True]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26193, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['sequence'].str.len() >= 20) & (df['sequence'].str.len() <=500)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "li2016_entries = set()\n",
    "for record in SeqIO.parse(\"li2016/li2016.fasta\", \"fasta\"):\n",
    "    pdb, chain = record.id.split('|')[1].split(':')\n",
    "    li2016_entries.add('%s_%s' % (pdb.lower(), chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['li2016'] = df.index.isin(li2016_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "li2016_testset = df[(df['li2016'] == True) & (df['less30'] == 1) & (df['cdhit'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518, 21)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li2016_testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exclude'] = df.index.isin(li2016_testset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26193, 22)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['exclude'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25675, 22)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get only entries after cd-hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21166, 22)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['cdhit'] == True]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Filter out half of negative sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11645, 22)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df[df['cc'] == 1], df[df['cc'] == 0].sample(frac=0.5)])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to assure the equal distribution of CC-residues and non-CC-residues in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_count = df[df['cc'] == 1].shape[0]\n",
    "nocc_count = df[df['cc'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2125, 212.5, 9520, 952.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_count, 0.1*cc_count, nocc_count, 0.1*nocc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00161479614645\n",
      "0.03041347094432709 0.030113536244352784 0.03334312853724531 0.00161479614645 1\n",
      "0.000258033827777\n",
      "0.03041347094432709 0.03036506285151086 0.03088113050706567 0.000258033827777 2\n",
      "0.000121864927236\n",
      "0.03041347094432709 0.030436439676504976 0.030192709822033006 0.000121864927236 14\n",
      "6.39369032481e-05\n",
      "0.03041347094432709 0.03042535873781495 0.030297484931318838 6.39369032481e-05 34\n",
      "6.06292943259e-05\n",
      "0.03041347094432709 0.03042486060813734 0.030303602019485468 6.06292943259e-05 38\n",
      "1.15024062088e-05\n",
      "0.03041347094432709 0.030411415596733396 0.030434420409150953 1.15024062088e-05 48\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "pos_cc = ''.join(df['socket_assignment'].tolist()).count('1')\n",
    "neg_cc = ''.join(df['socket_assignment'].tolist()).count('0')\n",
    "all_frac = (pos_cc/(pos_cc+neg_cc))\n",
    "score = 1\n",
    "best = 1\n",
    "it = 0\n",
    "while score > 0.00002:\n",
    "    it += 1\n",
    "    df_temp = df.copy()\n",
    "    test_pos = df_temp[(df_temp['cc'] == 1) & (df_temp['less30'] == True)].sample(random.randrange(200, 230))\n",
    "    test_neg = df_temp[(df_temp['cc'] == 0) & (df_temp['less30'] == True)].sample(random.randrange(920, 990))\n",
    "    test = pd.concat((test_pos, test_neg))\n",
    "    df_temp.drop(test_pos.index, inplace=True)\n",
    "    df_temp.drop(test_neg.index, inplace=True)\n",
    "    train = df_temp\n",
    "    train_pos_cc = ''.join(train['socket_assignment'].tolist()).count('1')\n",
    "    train_neg_cc = ''.join(train['socket_assignment'].tolist()).count('0')\n",
    "    train_frac = (train_pos_cc/(train_pos_cc+train_neg_cc))\n",
    "    test_pos_cc = ''.join(test['socket_assignment'].tolist()).count('1')\n",
    "    test_neg_cc = ''.join(test['socket_assignment'].tolist()).count('0')\n",
    "    test_frac = (test_pos_cc/(test_pos_cc+test_neg_cc))\n",
    "    score = np.std((train_frac, test_frac))\n",
    "    if score < best:\n",
    "        print(score)\n",
    "        best = score\n",
    "        print(all_frac, train_frac, test_frac, best, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10485, 22), (1160, 22))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train for 5-fold cross validation|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again equal distribution of CC and non-CC residues must be assured in each validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00225916966386 [0.028672398147568685, 0.030239752513534415, 0.03241549946786611, 0.033399634206565935, 0.027326000194685097] 1\n",
      "0.00170069282977 [0.030321885094984572, 0.02855723431894099, 0.03270583129194778, 0.031923456280171326, 0.02854991983105862] 2\n",
      "0.00111610343167 [0.03016846172916265, 0.031085387266697014, 0.03218259342476657, 0.029461114465152382, 0.029117047947351926] 4\n",
      "0.00107962152056 [0.02914814388567795, 0.031191939402601114, 0.03202419126798331, 0.029408579065656273, 0.030284475258345236] 9\n",
      "0.000686113687914 [0.03029827498023899, 0.030419904996057685, 0.031699511604074755, 0.029804394717648702, 0.02985170381199745] 15\n",
      "0.000448834292455 [0.030831185253635523, 0.03060875512995896, 0.030818870691762406, 0.030141652249134947, 0.029667544888882017] 43\n",
      "0.000373402399414 [0.03015175329461824, 0.03002597627159941, 0.03052280354993689, 0.031081387396568124, 0.03027036996478447] 113\n",
      "0.000225642912878 [0.030657628962088252, 0.030200961429332637, 0.030092412223971077, 0.030496023921220076, 0.030613262033339785] 151\n",
      "0.000102782015543 [0.030339666873019352, 0.030453441872375493, 0.030427636412077803, 0.03026708898602321, 0.03056893816551248] 1939\n"
     ]
    }
   ],
   "source": [
    "score = 1\n",
    "best = 1\n",
    "it = 0\n",
    "while score > 0.0002:\n",
    "    it += 1\n",
    "    fractions = []\n",
    "    df_temp = train.copy()\n",
    "    df_temp = df_temp.sample(frac=1)\n",
    "    splits = np.array_split(df_temp, 5)\n",
    "    for split in splits:\n",
    "        pos_cc = ''.join(split['socket_assignment'].tolist()).count('1')\n",
    "        neg_cc = ''.join(split['socket_assignment'].tolist()).count('0')\n",
    "        frac = (pos_cc/(pos_cc+neg_cc))\n",
    "        fractions.append(frac)\n",
    "    score = np.std(fractions)\n",
    "    if score < best:\n",
    "        best = score\n",
    "        print(score, fractions, it)\n",
    "        c = 1\n",
    "        for split in splits:\n",
    "            split['val'] = c\n",
    "            if c == 1:\n",
    "                train_val = split\n",
    "            else:\n",
    "                train_val = pd.concat([train_val, split])\n",
    "            c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2097, 23), (2097, 23), (2097, 23), (2097, 23), (2097, 23))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val[train_val['val'] == 1].shape, train_val[train_val['val'] == 2].shape, train_val[train_val['val'] == 3].shape, train_val[train_val['val'] == 4].shape, train_val[train_val['val'] == 5].shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.to_pickle('out/train_data.p')\n",
    "train_val.to_csv('out/train_data.csv')\n",
    "test.to_pickle('out/test_data.p')\n",
    "test.to_csv('out/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li2016_testset.to_pickle('out/li2016.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li2016_testset.to_csv('out/li2016.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
