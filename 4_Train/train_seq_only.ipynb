{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from lbs.dl.encoders import enc_seq_onehot, enc_label\n",
    "import pickle\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open('./../3_Train_Test_Split/out/train_data.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    entries = []\n",
    "    for entry, seq, label in zip(df.index, df['sequence'].tolist(), df['socket_assignment'].tolist()):\n",
    "        if len(seq) <= 500:\n",
    "            pad_left = random.randint(0, 500 - len(seq))\n",
    "            sequences.append(enc_seq_onehot(seq, pad_length=500, pad_left=pad_left))\n",
    "            labels.append(enc_label(label, pad_length=500, pad_left=pad_left))\n",
    "            entries.append(entry)\n",
    "    return (np.asarray(sequences), np.asarray(labels), entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(pred, enc_seq):\n",
    "    decoded_preds = []\n",
    "    for entry_pred, entry in zip(pred, enc_seq):\n",
    "        decoded_pred = []\n",
    "        for pos_pred, pos_seq in zip(entry_pred, entry):\n",
    "            if not np.array_equal(pos_seq, np.zeros(20)):\n",
    "                decoded_pred.append(pos_pred[1])\n",
    "        decoded_preds.append(np.asarray(decoded_pred))\n",
    "    return np.asarray(decoded_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from lbs.dl.logger import Logger\n",
    "from lbs.dl.metrics import total_accuracy\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SpatialDropout1D, SpatialDropout2D, MaxPooling1D, MaxPooling2D, Dense, TimeDistributed, Convolution1D, BatchNormalization,Input,merge,LSTM, Dropout,Embedding,Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "def wcc(weights):\n",
    "    weights = K.variable(weights)\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    return loss\n",
    "weights = np.array([1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    lr = 0.0005\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(64, 28, padding='same', activation='relu', kernel_regularizer=l2(0.0001), input_shape=(500, 20)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution1D(64, 21, padding='same',  activation='relu', kernel_regularizer=l2(0.0001)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dense(2, activation='softmax', name='out'))\n",
    "    adam = Adam(lr=lr)\n",
    "    model.compile(optimizer=adam, loss=wcc(weights), metrics=[total_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV #1:\n",
      "2179\n",
      "CV #2:\n",
      "4358\n",
      "CV #3:\n",
      "6537\n",
      "CV #4:\n",
      "8716\n",
      "CV #5:\n",
      "10895\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "for i in range(1, 6):\n",
    "    print('CV #%s:' % i)\n",
    "    ch1 = Logger(lab_pos=1, out_path='models/final_seq/', out_fn='final_seq_%s.h5' % (i), out_log='final_seq.txt' )\n",
    "    callbacks_list = [ch1]\n",
    "    model = Model()\n",
    "    ### Get data\n",
    "    val_df = df[df['val'] == i]\n",
    "    train_df = df[df['val'] != i]\n",
    "    train_data= encode(train_df)\n",
    "    valid_data = encode(val_df)\n",
    "    ### Train\n",
    "    \"\"\"h = model.fit(train_data[0], train_data[1],\n",
    "                  validation_data = (valid_data[0], valid_data[1]),\n",
    "                  batch_size=64,\n",
    "                  epochs=50,\n",
    "                  verbose=0, callbacks=callbacks_list)\"\"\"\n",
    "    ### Predict\n",
    "    model.load_weights('models/final_seq/final_seq_%s.h5' % i)\n",
    "    preds = model.predict(valid_data[0])\n",
    "    ### Decode predictions and add results to dict\n",
    "    decoded_preds = decode(preds, valid_data[0])\n",
    "    for entry, decoded_pred in zip(valid_data[2], decoded_preds):\n",
    "        assignment  = ''.join(str(int(label)) for label in np.rint(decoded_pred))\n",
    "        cv_results[entry] = assignment\n",
    "    print(len(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10895, (10895, 20))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_results), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deepcoil = pd.DataFrame.from_dict(cv_results, orient='index')\n",
    "df_deepcoil.columns = ['deepcoil_assignment']\n",
    "df = pd.concat([df, df_deepcoil], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('out/seq/cv_results.p')\n",
    "df.to_csv('out/seq/cv_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pickle.load(open('./../3_Train_Test_Split/out/test_data.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = encode(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble_results = {}\n",
    "for i in range(1, 6):\n",
    "    model.load_weights('models/final_seq/final_seq_%s.h5' % i)\n",
    "    preds = model.predict(test_data[0])\n",
    "    decoded_preds = decode(preds, test_data[0])\n",
    "    for decoded_pred, entry in zip(decoded_preds, test_data[2]):\n",
    "        if i == 1:\n",
    "            test_ensemble_results[entry] = decoded_pred\n",
    "        else:\n",
    "            test_ensemble_results[entry] = np.vstack((test_ensemble_results[entry], decoded_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_avg_results = {}\n",
    "for key, value in test_ensemble_results.items():\n",
    "    avg_results = np.average(value, axis=0)\n",
    "    assignment  = ''.join(str(int(label)) for label in np.rint(avg_results))\n",
    "    test_avg_results[key] = assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, (1200, 19))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_avg_results), df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deepcoil = pd.DataFrame.from_dict(test_avg_results, orient='index')\n",
    "df_deepcoil.columns = ['deepcoil_assignment']\n",
    "df_test = pd.concat([df_test, df_deepcoil], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_pickle('out/seq/test_results.p')\n",
    "df_test.to_csv('out/seq/test_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
